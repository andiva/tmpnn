{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, PowerTransformer, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from tmpnn import Classification, L1, L2, Lyapunov1, Lyapunov2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import autograph\n",
    "tf.keras.utils.set_random_seed(17)\n",
    "\n",
    "def balanced_log_loss(y_true, p_pred):\n",
    "    N0 = np.sum(1-y_true)\n",
    "    N1 = np.sum(y_true)\n",
    "\n",
    "    p0 = K.clip(p_pred[:,0]/p_pred.sum(1), 1e-15, 1 - 1e-15)\n",
    "    p1 = K.clip(p_pred[:,1]/p_pred.sum(1), 1e-15, 1 - 1e-15)\n",
    "\n",
    "    log_loss_0 = -np.sum((1-y_true) * np.log(p0)) / N0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p1)) / N1\n",
    "    return (log_loss_0 + log_loss_1)/2\n",
    "\n",
    "def balanced_log_loss1(y_true, p_pred):\n",
    "    N0 = np.sum(1-y_true)\n",
    "    N1 = np.sum(y_true)\n",
    "\n",
    "    p0 = K.clip((1-p_pred), 1e-15, 1 - 1e-15)\n",
    "    p1 = K.clip(p_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    log_loss_0 = -np.sum((1-y_true) * np.log(p0)) / N0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p1)) / N1\n",
    "    return (log_loss_0 + log_loss_1)/2\n",
    "\n",
    "def blloss(p_true, p_pred):\n",
    "    N0 = K.sum(p_true[:,0])\n",
    "    N1 = K.sum(p_true[:,1])\n",
    "\n",
    "    p0 = K.clip(p_pred[:,0]/K.sum(p_pred,1), 1e-15, 1 - 1e-15)\n",
    "    p1 = K.clip(p_pred[:,1]/K.sum(p_pred,1), 1e-15, 1 - 1e-15)\n",
    "\n",
    "    log_loss_0 = -K.sum(p_true[:,0] * K.log(p0)) / N0\n",
    "    log_loss_1 = -K.sum(p_true[:,1] * K.log(p1)) / N1\n",
    "    return (log_loss_0 + log_loss_1)/2\n",
    "shifted_blloss=autograph.experimental.do_not_convert(lambda t,p: blloss(t+0.5,p+0.5))\n",
    "\n",
    "def blloss1(p_true, p_pred):\n",
    "    N0 = K.sum(1-p_true)\n",
    "    N1 = K.sum(p_true)\n",
    "\n",
    "    p0 = K.clip((1-p_pred), 1e-15, 1 - 1e-15)\n",
    "    p1 = K.clip(p_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    log_loss_0 = -K.sum((1-p_true) * K.log(p0)) / N0\n",
    "    log_loss_1 = -K.sum(p_true * K.log(p1)) / N1\n",
    "    return (log_loss_0 + log_loss_1)/2\n",
    "shifted_blloss1=autograph.experimental.do_not_convert(lambda t,p: blloss1(t+0.5,p+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "X, Y = df.drop(columns=['Id','Class']), np.asfarray(df['Class'])\n",
    "X['EJ'] = LabelEncoder().fit_transform(X['EJ'])-0.5\n",
    "\n",
    "X_tr, X_val, Y_tr, Y_val = train_test_split(X, Y, test_size=0.3, random_state=17)\n",
    "\n",
    "pt = PowerTransformer()\n",
    "mms = MinMaxScaler((-0.5,0.5))\n",
    "X_tr = mms.fit_transform(pt.fit_transform(X_tr))\n",
    "X_val = np.clip(mms.transform(pt.transform(X_val)),-1,1)\n",
    "X = np.clip(mms.transform(pt.transform(X)),-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.008024114076603505\n",
      "  val 0.35380013551892775\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(verbose=False)\n",
    "cat.fit(X_tr, Y_tr, eval_set=(X_val, Y_val))\n",
    "print('train', balanced_log_loss(Y_tr, cat.predict_proba(X_tr)))\n",
    "print('  val', balanced_log_loss(Y_val,cat.predict_proba(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.1281564531629268\n",
      "  val 0.1954224844550201\n"
     ]
    }
   ],
   "source": [
    "# -0.5, 0.5 labels n=2\n",
    "f=cat.get_feature_importance()>1\n",
    "model = Classification(X[:,f].shape[1], 2, 2, 7, regularizer=L1())\n",
    "\n",
    "model.set_learning_rate(5e-3, metrics=shifted_blloss, loss='mse')\n",
    "history = model.fit(X_tr[:,f], np.column_stack([0.5-Y_tr, Y_tr-0.5]), epochs=100,\n",
    "                     validation_data=(X_val[:,f], np.column_stack([0.5-Y_val,Y_val-0.5])))\n",
    "model.set_learning_rate(5e-5, metrics=shifted_blloss, loss=shifted_blloss)\n",
    "history = model.fit(X_tr[:,f], np.column_stack([0.5-Y_tr, Y_tr-0.5]), epochs=100, stop_monitor='val_<lambda>', patience=0,\n",
    "                     validation_data=(X_val[:,f], np.column_stack([0.5-Y_val,Y_val-0.5])))\n",
    "print('train', balanced_log_loss(Y_tr, model.predict_proba(X_tr[:,f])+0.5))\n",
    "print('  val', balanced_log_loss(Y_val,model.predict_proba(X_val[:,f])+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.10857282717878322\n",
      "  val 0.20035949477555381\n"
     ]
    }
   ],
   "source": [
    "#   0,   1 labels n=2\n",
    "f=cat.get_feature_importance()>1\n",
    "model = Classification(X[:,f].shape[1], 2, 2, 7, regularizer=L1())\n",
    "\n",
    "model.set_learning_rate(5e-3, metrics=blloss, loss='mse')\n",
    "history = model.fit(X_tr[:,f], np.column_stack([1-Y_tr,Y_tr]), epochs=100, stop_monitor='val_blloss', patience=10,\n",
    "                     validation_data=(X_val[:,f], np.column_stack([1-Y_val,Y_val])))\n",
    "model.set_learning_rate(5e-5, metrics=blloss, loss=blloss)\n",
    "history = model.fit(X_tr[:,f], np.column_stack([1-Y_tr,Y_tr]), epochs=100, stop_monitor='val_blloss', patience=0,\n",
    "                     validation_data=(X_val[:,f], np.column_stack([1-Y_val,Y_val])))\n",
    "print('train', balanced_log_loss(Y_tr, model.predict_proba(X_tr[:,f])))\n",
    "print('  val', balanced_log_loss(Y_val,model.predict_proba(X_val[:,f])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.1306472894912747\n",
      "  val 0.2151165014610832\n"
     ]
    }
   ],
   "source": [
    "# -0.5, 0.5 labels n=1\n",
    "f=cat.get_feature_importance()>1\n",
    "model = Classification(X[:,f].shape[1], 1, 2, 7, regularizer=L1())\n",
    "\n",
    "model.set_learning_rate(5e-3, metrics=shifted_blloss1, loss='mse')\n",
    "history = model.fit(X_tr[:,f], Y_tr.reshape(-1,1)-0.5, epochs=100, stop_monitor='val_<lambda>', patience=10,\n",
    "                     validation_data=(X_val[:,f], Y_val.reshape(-1,1)-0.5))\n",
    "model.set_learning_rate(5e-5, metrics=shifted_blloss1, loss=shifted_blloss1)\n",
    "history = model.fit(X_tr[:,f], Y_tr.reshape(-1,1)-0.5, epochs=100, stop_monitor='val_<lambda>', patience=0,\n",
    "                     validation_data=(X_val[:,f], Y_val.reshape(-1,1)-0.5))\n",
    "print('train', balanced_log_loss1(Y_tr, model.predict_proba(X_tr[:,f])[:,1]+0.5))\n",
    "print('  val', balanced_log_loss1(Y_val,model.predict_proba(X_val[:,f])[:,1]+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.12878092867693006\n",
      "  val 0.21383419008701682\n"
     ]
    }
   ],
   "source": [
    "# 0, 1 labels n=1\n",
    "f=cat.get_feature_importance()>1\n",
    "model = Classification(X[:,f].shape[1], 1, 2, 7, regularizer=L1())\n",
    "\n",
    "model.set_learning_rate(5e-3, metrics=blloss1, loss='mse')\n",
    "history = model.fit(X_tr[:,f], Y_tr.reshape(-1,1), epochs=100, stop_monitor='val_blloss1', patience=10,\n",
    "                     validation_data=(X_val[:,f], Y_val.reshape(-1,1)))\n",
    "model.set_learning_rate(5e-5, metrics=blloss1, loss=blloss1)\n",
    "history = model.fit(X_tr[:,f], Y_tr.reshape(-1,1), epochs=100, stop_monitor='val_blloss1', patience=0,\n",
    "                     validation_data=(X_val[:,f], Y_val.reshape(-1,1)))\n",
    "print('train', balanced_log_loss(Y_tr, model.predict_proba(X_tr[:,f])))\n",
    "print('  val', balanced_log_loss(Y_val,model.predict_proba(X_val[:,f])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b629441d686445519a9b2d8bebf7b7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51415f34b14e4f03b377253eaa1dfb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.04359397767622917\n",
      "  val 0.4897101571189198\n"
     ]
    }
   ],
   "source": [
    "# 0, 1 labels n=1 logit\n",
    "f=cat.get_feature_importance()>1\n",
    "model = Classification(X[:,f].shape[1], 1, 2, 7, regularizer=L1(), logit=True, verbose=2)\n",
    "\n",
    "model.set_learning_rate(5e-3, metrics=blloss1, loss='mse')\n",
    "history = model.fit(X_tr[:,f], Y_tr.reshape(-1,1), epochs=100, #stop_monitor='val_blloss1', patience=10,\n",
    "                     validation_data=(X_val[:,f], Y_val.reshape(-1,1)))\n",
    "model.set_learning_rate(5e-5, metrics=blloss1, loss=blloss1)\n",
    "history = model.fit(X_tr[:,f], Y_tr.reshape(-1,1), epochs=100, #stop_monitor='val_blloss1', patience=0,\n",
    "                     validation_data=(X_val[:,f], Y_val.reshape(-1,1)))\n",
    "print('train', balanced_log_loss(Y_tr, model.predict_proba(X_tr[:,f])))\n",
    "print('  val', balanced_log_loss(Y_val,model.predict_proba(X_val[:,f])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=np.array([ True,  True, False,  True, False, False, False, False,  True,\n",
    "            False, False, False,  True, False, False,  True,  True,  True,\n",
    "            False, False, False,  True,  True, False, False,  True,  True,\n",
    "            False,  True,  True,  True,  True,  True, False,  True,  True,\n",
    "             True,  True, False, False,  True, False,  True,  True,  True,\n",
    "             True,  True,  True,  True, False, False,  True,  True,  True,\n",
    "            False,  True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "X, Y = df.drop(columns=['Id','Class']), np.asfarray(df['Class'])\n",
    "\n",
    "le = LabelEncoder()\n",
    "pt = PowerTransformer()\n",
    "mms = MinMaxScaler((-0.5,0.5))\n",
    "\n",
    "X['EJ'] = le.fit_transform(X['EJ'])-0.5\n",
    "X = mms.fit_transform(pt.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "from tensorflow import autograph\n",
    "shifted_blloss=autograph.experimental.do_not_convert(lambda t,p: blloss(t+0.5,p+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11676100528982172"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classification(X[:,f].shape[1], 2, 2, 7, verbose=0, regularizer=L1())\n",
    "model.set_learning_rate(5e-3, metrics=shifted_blloss, loss='mse')\n",
    "history = model.fit(X[:,f], np.column_stack([0.5-Y, Y-0.5]), epochs=100)\n",
    "model.set_learning_rate(5e-5, metrics=shifted_blloss, loss=shifted_blloss)\n",
    "history = model.fit(X[:,f], np.column_stack([0.5-Y, Y-0.5]), epochs=100)\n",
    "balanced_log_loss(Y, model.predict_proba(X[:,f])+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.vstack(model.pnn.get_weights())).to_csv('weights.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.read_csv('weights.csv').values\n",
    "W = (weights[0], weights[1:f.sum()+3], weights[f.sum()+3:])\n",
    "\n",
    "def tm_map(x, weights=None, steps=7):\n",
    "    W0, W1, W2 = weights\n",
    "    ans = np.asfarray(np.hstack((x, np.zeros((x.shape[0], 2)))))\n",
    "    for _ in range(steps):\n",
    "        ans = W0 + np.dot(ans, W1) + np.dot((ans[:,:,None]*ans[:,None,:]).reshape(ans.shape[0],-1), W2)\n",
    "    return ans[:,-2:]+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11676100684587581"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(y_true, p_pred):\n",
    "    N0 = np.sum(1 - y_true)\n",
    "    N1 = np.sum(y_true)\n",
    "\n",
    "    p0 = K.clip(p_pred[:,0]/p_pred.sum(1), 1e-15, 1 - 1e-15)\n",
    "    p1 = K.clip(p_pred[:,1]/p_pred.sum(1), 1e-15, 1 - 1e-15)\n",
    "\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p0)) / N0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p1)) / N1\n",
    "    return (log_loss_0 + log_loss_1)/2\n",
    "score(Y, tm_map(X[:,f], W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "X_test = test.fillna(df.mean(numeric_only=True)).drop(columns=['Id'])\n",
    "X_test['EJ'] = le.transform(X_test['EJ'])-0.5\n",
    "X_test = mms.transform(pt.transform(X_test))\n",
    "submit = test[['Id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  class_0  class_1\n",
       "0  00eed32682bb      0.0      1.0\n",
       "1  010ebe33f668      0.0      1.0\n",
       "2  02fa521e1838      0.0      1.0\n",
       "3  040e15f562a2      0.0      1.0\n",
       "4  046e85c7cc7f      0.0      1.0"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tm_map(np.clip(X_test[:,f],-1, 1), W)\n",
    "submit[\"class_0\"] = np.clip( pred[:,0]/pred.sum(axis=1) ,0,1)\n",
    "submit[\"class_1\"] = np.clip( pred[:,1]/pred.sum(axis=1) ,0,1)\n",
    "submit=submit.fillna(0.5)\n",
    "# submit.to_csv('/kaggle/working/submission.csv',index=False)\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  class_0  class_1\n",
       "0  00eed32682bb      1.0      0.0\n",
       "1  010ebe33f668      1.0      0.0\n",
       "2  02fa521e1838      1.0      0.0\n",
       "3  040e15f562a2      1.0      0.0\n",
       "4  046e85c7cc7f      1.0      0.0"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.clip( tm_map(np.clip(X_test[:,f],-1, 1), W) ,0,1)\n",
    "submit[\"class_0\"] = pred[:,0]/pred.sum(axis=1)\n",
    "submit[\"class_1\"] = pred[:,1]/pred.sum(axis=1)\n",
    "submit=submit.fillna(0.5)\n",
    "# submit.to_csv('/kaggle/working/submission.csv',index=False)\n",
    "submit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# legacy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history, model_=None, pred=None, metric='blloss'):\n",
    "    plt.figure(figsize=(8,2))\n",
    "\n",
    "    ax = plt.subplot(121)\n",
    "    ax.set_title('tf balanced log loss')\n",
    "    if model_:\n",
    "        label_tr=f'train {balanced_log_loss(Y_tr, model_.predict_proba(X_tr)):.2f}'\n",
    "        label_val=f'val {balanced_log_loss(Y_val, model_.predict_proba(X_val)):.2f}'\n",
    "    elif pred:\n",
    "        label_tr=f'train {balanced_log_loss(Y_tr, pred[0]):.2f}'\n",
    "        label_val=f'val {balanced_log_loss(Y_val, pred[1]):.2f}'\n",
    "    else:\n",
    "        label_tr='train'\n",
    "        label_val='val'\n",
    "    ax.plot(history.history[metric], label=label_tr)\n",
    "    ax.plot(history.history['val_'+metric], label=label_val)\n",
    "    ax.legend()\n",
    "\n",
    "    ax = plt.subplot(122)\n",
    "    ax.set_title('loss')\n",
    "    ax.plot(history.history['loss'])\n",
    "    ax.plot(history.history['val_loss'])\n",
    "    ax.yaxis.tick_right()\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
